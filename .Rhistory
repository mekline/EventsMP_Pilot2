mutate(ROIName = 'Localizer Average') %>%
mutate(nVoxels = 0)
allSigChange <- union(allSigChange, avgSigChange)
#(Gets mad that there's a new ROIName level :p)
allSigChange$ROIName <- as.factor(allSigChange$ROIName)
#Next, get the table that we'll be making the graphs from: for each region (including the average region), take all
#the individual signal changes and calculate a mean, a standard error (incase we want it)
#and bootstrapped CIs (which we'll actually use)
sterr <- function(mylist){
my_se = sd(mylist)/sqrt(length(mylist))
return(my_se)
}
#bootstrapped 95% confidence intervals! calculate them from allSigChange
#then merge into mystats
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
toGraph <- allSigChange %>%
group_by(ROIName, Contrast, Localizer, ROISystem, TaskCrit) %>%
summarize(meanSig = mean(SignalChange), sterr = sterr(SignalChange),
bootup = bootup(SignalChange), bootdown = bootdown(SignalChange))%>%
mutate(ROIGroup = ifelse(ROIName == 'Localizer Average','across ROIs','individual ROIs'))
#Force some factor orderings here, they are finicky!
toGraph$ROIName <- factor(toGraph$ROIName, levels = c("LIFGorb",
"LIFG",
"LMFG",
"LAntTemp",
"LPostTemp",
"LAngG",
"Localizer Average"))
toGraph$ROIGroup <- factor(toGraph$ROIGroup, levels = c("across ROIs",
"individual ROIs"))
toGraph <- toGraph %>%
arrange(ROIGroup, ROIName)
#########
# Graphs!
#########
#Now we can use the information stored in mystats to make pretty graphs! This could be done in excel too by printing mystats
#Change to figs output folder
figdir = paste(getwd(),'figs')
setwd(figdir)
#Subset and rename for language localiser
LangLoc_LangCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='langlocSN') %>%
filter(Contrast %in% c('S','N'))
LangLoc_EvCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='EventsMP') %>%
filter(Contrast %in% c("Cont","DiffAll","SameAll","SameMan","SamePath","SameAg"))
#More factor reordering
LangLoc_LangCrit$Contrast <- factor(LangLoc_LangCrit$Contrast, levels = c("S","N"))
LangLoc_LangCrit <- LangLoc_LangCrit %>%
arrange(ROIGroup, ROIName, Contrast)
LangLoc_EvCrit$Contrast <- factor(LangLoc_EvCrit$Contrast, levels = c("DiffAll","SameMan",
"SamePath","SameAg",
"SameAll","Cont"))
LangLoc_EvCrit <- LangLoc_EvCrit %>%
arrange(ROIGroup, ROIName, Contrast)
#Graphing function!
makeBar = function(plotData, fileName = 'TEST NAME', ylow=-0.5,yhigh=2.5, mycolors = c("gray35", "gray60")) {
#freeze factor orders, AGAIN
plotData$ROIName <- factor(plotData$ROIName, levels = unique(plotData$ROIName))
plotData$ROIGroup <- factor(plotData$ROIGroup, levels = unique(plotData$ROIGroup))
myfi = paste(fileName, '.jpg', sep="")#filename
print(myfi)
ggplot(data=plotData, aes(x=ROIName, y=meanSig, fill=Contrast)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(ylow-0.5,yhigh+0.5)) +
scale_y_continuous(breaks = seq(ylow-0.5, yhigh+0.5, 0.5))+
xlab('') +
ylab(str_wrap('% signal change over fixation', width=18)) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(text = element_text(size = 25)) +
facet_grid(~ROIGroup, scale='free_x', space='free_x') +
theme(strip.background = element_blank()) +
theme(strip.text = element_blank())
ggsave(filename=myfi, width=length(unique(plotData$ROIName))*2.2, height=6.1)
}
makeBar(LangLoc_LangCrit, 'LangLoc_LangCrit')
makeBar(LangLoc_EvCrit, 'LangLoc_EventsMPCrit', yhigh=0.5)
makeBar(LangLoc_EvCrit, 'LangLoc_EventsMPCrit', yhigh=1)
setwd("~/Dropbox/_Projects/AgentPatient - fMRI/AgentPatient_Pilot Repo/Analysis_pilot2")
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_langloc_crit_agpat_20171218',sep='')
myOutputFolder = getwd()
myFilename = 'loc_langloc_crit_agpat_20171218.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files (actually they are formatted better now, thanks A.!) and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_langloc_crit_langloc_20171218',sep='')
myOutputFolder = getwd()
myFilename = 'loc_langloc_crit_langloc_20171218.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files (actually they are formatted better now, thanks A.!) and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
setwd("~/Dropbox/_Projects/AgentPatient - fMRI/AgentPatient_Pilot Repo/Analysis_pilot2")
myResults = read.csv('loc_langloc_crit_agpat_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'AgPat')
allSigChange = read.csv('loc_langloc_crit_langloc_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'langlocSN')
allSigChange = rbind(allSigChange, myResults)
rm(list = ls())
library(bootstrap)
library(dplyr)
library(tidyr)
library(ggplot2)
library(stringr)
##SET YOUR DIRECTORY!!!
########
#READ IN DATA
########
#Here, we read in all those files, calculate a whole passle of mean and standard error bars, and then make graphs
myResults = read.csv('loc_langloc_crit_agpat_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'AgPat')
allSigChange = read.csv('loc_langloc_crit_langloc_20171218.csv',
colClasses = c("factor","factor", "factor","numeric","numeric")) %>%
mutate(Localizer = 'langlocSN') %>%
mutate(ROISystem = 'LHLang') %>%
mutate(TaskCrit = 'langlocSN')
allSigChange = rbind(allSigChange, myResults)
View(allSigChange)
avgSigChange = allSigChange %>%
group_by(Subject,Contrast,ROISystem,Localizer,TaskCrit) %>%
summarize('SignalChange' = mean(SignalChange)) %>%
mutate(ROIName = 'Localizer Average') %>%
mutate(nVoxels = 0)
allSigChange <- union(allSigChange, avgSigChange)
#(Gets mad that there's a new ROIName level :p)
allSigChange$ROIName <- as.factor(allSigChange$ROIName)
#Next, get the table that we'll be making the graphs from: for each region (including the average region), take all
#the individual signal changes and calculate a mean, a standard error (incase we want it)
#and bootstrapped CIs (which we'll actually use)
sterr <- function(mylist){
my_se = sd(mylist)/sqrt(length(mylist))
return(my_se)
}
#bootstrapped 95% confidence intervals! calculate them from allSigChange
#then merge into mystats
bootup <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.975)[1])
}
bootdown <- function(mylist){
foo <- bootstrap(mylist, 1000, mean)
return(quantile(foo$thetastar, 0.025)[1])
}
toGraph <- allSigChange %>%
group_by(ROIName, Contrast, Localizer, ROISystem, TaskCrit) %>%
summarize(meanSig = mean(SignalChange), sterr = sterr(SignalChange),
bootup = bootup(SignalChange), bootdown = bootdown(SignalChange))%>%
mutate(ROIGroup = ifelse(ROIName == 'Localizer Average','across ROIs','individual ROIs'))
#Force some factor orderings here, they are finicky!
toGraph$ROIName <- factor(toGraph$ROIName, levels = c("LIFGorb",
"LIFG",
"LMFG",
"LAntTemp",
"LPostTemp",
"LAngG",
"Localizer Average"))
toGraph$ROIGroup <- factor(toGraph$ROIGroup, levels = c("across ROIs",
"individual ROIs"))
toGraph <- toGraph %>%
arrange(ROIGroup, ROIName)
View(toGraph)
#Subset and rename for language localiser
LangLoc_LangCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='langlocSN') %>%
filter(Contrast %in% c('S','N'))
LangLoc_APCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='AgPat') %>%
filter(Contrast %in% c("agt","pat"))
makeBar = function(plotData, fileName = 'TEST NAME', ylow=-0.5,yhigh=2.5, mycolors = c("gray35", "gray60")) {
#freeze factor orders, AGAIN
plotData$ROIName <- factor(plotData$ROIName, levels = unique(plotData$ROIName))
plotData$ROIGroup <- factor(plotData$ROIGroup, levels = unique(plotData$ROIGroup))
myfi = paste(fileName, '.jpg', sep="")#filename
print(myfi)
ggplot(data=plotData, aes(x=ROIName, y=meanSig, fill=Contrast)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(ylow-0.5,yhigh+0.5)) +
scale_y_continuous(breaks = seq(ylow-0.5, yhigh+0.5, 0.5))+
xlab('') +
ylab(str_wrap('% signal change over fixation', width=18)) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(text = element_text(size = 25)) +
facet_grid(~ROIGroup, scale='free_x', space='free_x') +
theme(strip.background = element_blank()) +
theme(strip.text = element_blank())
ggsave(filename=myfi, width=length(unique(plotData$ROIName))*2.2, height=6.1)
}
makeBar(LangLoc_LangCrit, 'LangLoc_LangCrit')
makeBar(LangLoc_EvCrit, 'LangLoc_APCrit')
makeBar(LangLoc_APCrit, 'LangLoc_APCrit')
figdir = paste(getwd(),'figs')
setwd(figdir)
#Subset and rename for language localiser
LangLoc_LangCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='langlocSN') %>%
filter(Contrast %in% c('S','N'))
LangLoc_APCrit <- filter(toGraph, Localizer =='langlocSN',TaskCrit =='AgPat') %>%
filter(Contrast %in% c("agt","pat"))
#More factor reordering
LangLoc_LangCrit$Contrast <- factor(LangLoc_LangCrit$Contrast, levels = c("S","N"))
LangLoc_LangCrit <- LangLoc_LangCrit %>%
arrange(ROIGroup, ROIName, Contrast)
LangLoc_APCrit$Contrast <- factor(LangLoc_APCrit$Contrast, levels = c("agt","pat"))
LangLoc_APCrit <- LangLoc_APCrit %>%
arrange(ROIGroup, ROIName, Contrast)
#Graphing function!
makeBar = function(plotData, fileName = 'TEST NAME', ylow=-0.5,yhigh=2.5, mycolors = c("gray35", "gray60")) {
#freeze factor orders, AGAIN
plotData$ROIName <- factor(plotData$ROIName, levels = unique(plotData$ROIName))
plotData$ROIGroup <- factor(plotData$ROIGroup, levels = unique(plotData$ROIGroup))
myfi = paste(fileName, '.jpg', sep="")#filename
print(myfi)
ggplot(data=plotData, aes(x=ROIName, y=meanSig, fill=Contrast)) +
geom_bar(position=position_dodge(), stat="identity") +
geom_errorbar(aes(ymin=bootdown, ymax=bootup), colour="black", width=.1, position=position_dodge(.9)) +
coord_cartesian(ylim=c(ylow-0.5,yhigh+0.5)) +
scale_y_continuous(breaks = seq(ylow-0.5, yhigh+0.5, 0.5))+
xlab('') +
ylab(str_wrap('% signal change over fixation', width=18)) +
theme_bw() +
theme(legend.key = element_blank()) +
theme(text = element_text(size = 25)) +
facet_grid(~ROIGroup, scale='free_x', space='free_x') +
theme(strip.background = element_blank()) +
theme(strip.text = element_blank())
ggsave(filename=myfi, width=length(unique(plotData$ROIName))*2.2, height=6.1)
}
makeBar(LangLoc_LangCrit, 'LangLoc_LangCrit')
makeBar(LangLoc_APCrit, 'LangLoc_APCrit')
setwd("~/Dropbox/_Projects/TriangleEventsMP - fMRI/EventsMP_Pilot2")
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_mdloc_crit_eventsMP_20171230',sep='')
myOutputFolder = getwd()
myFilename = 'loc_mdloc_crit_eventsMP_20171230.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
#load_spmss_results
#
#This file loads the output of one of the results.csv files produced by the toolbox into R.
#If I knew more about the mat file produced you could probably get all of this stuff out of
#there too.  But anyway this gets the mROI_data.csv file, sorts out its structure
#and reorganizes the data into proper longform. Take your analysis from there or save the result in a csv.
####
#Stuff to change!
myResultsFolder = paste(getwd(),'/loc_mdloc_crit_mdloc_20171230',sep='')
myOutputFolder = getwd()
myFilename = 'loc_mdloc_crit_mdloc_20171230.csv'
toSave = 1
#(Resulting data struct stored in variable myfile, to use directory)
####
# Leave alone unless feeling fancy
library(dplyr)
library(tidyr)
library(stringr)
setwd(myResultsFolder)
#Open the weirdly formatted files and get just the table we want.
myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
names(myfile) = c('ROIName','Subject','Contrast','nVoxels','SignalChange')
if(toSave){
setwd(myOutputFolder)
zz <- file(myFilename, "w")
write.csv(myfile, zz, row.names=FALSE)
close(zz)
}
# #### Old version, pre PL2017
# #Leave the rest alone unless you're feeling fancy
#
# library(dplyr)
# library(tidyr)
# library(stringr)
#
# setwd(myResultsFolder)
#
# #Open the weirdly formatted files and get just the table we want.
# myfile  = read.csv('spm_ss_mROI_data.csv',sep=',', skip=1, header=FALSE)
# lastsub = ncol(myfile)
# myfile= myfile[complete.cases(myfile[,lastsub]),]#drop things past the individual % changes....
#
# #To add: Look at the # of ROI parcels and their sizes, declare this to be a particular
# #localizer, provide names for parcels. Also could add all that as an optional function arg.
#
# extract_val <- function(mystring, mynum){# fn to extract subject & contrast numbers
#   foo = str_split(mystring, "\\.")
#   myval = unlist(foo[[1]][mynum])
#   return(myval)
#
# }
#
# #Make the data beautiful and longform.
# myfile[] <- lapply(myfile, as.character) #(Everything's a string, no factors)
# myfile <- myfile %>%
#   gather("Subject_and_Cont", "sigChange", Subject.1.1.:ncol(myfile)) %>%
#   rowwise() %>%
#   mutate(SubjectNumber = extract_val(Subject_and_Cont, 2)) %>%
#   mutate(Contrast = extract_val(Subject_and_Cont, 3)) %>%
#   select(-Subject_and_Cont) %>%
#   rename(ROI = ROI.)
#
#
# #Optional: print back out a nice file with a more informative name.
# if(toSave){
#   setwd(myOutputFolder)
#   zz <- file(myFilename, "w")
#   write.csv(myfile, zz, row.names=FALSE)
#   close(zz)
# }
